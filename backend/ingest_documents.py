import os
from dotenv import load_dotenv
from pinecone import Pinecone, ServerlessSpec
from langchain_community.document_loaders import (
    PyPDFLoader,
    UnstructuredWordDocumentLoader,
    TextLoader,
    UnstructuredHTMLLoader,
    UnstructuredMarkdownLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Pinecone as LangchainPinecone

# üõ†Ô∏è Chargement des variables d'environnement
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")
DOCS_FOLDER = "C:/Users/rahma/Downloads/chatbot-project/data/docs"

# üîå Initialisation Pinecone
pc = Pinecone(api_key=PINECONE_API_KEY)

# üîß Cr√©ation de l‚Äôindex si n√©cessaire
if PINECONE_INDEX_NAME not in pc.list_indexes().names():
    pc.create_index(
        name=PINECONE_INDEX_NAME,
        dimension=384,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region=PINECONE_ENVIRONMENT)
    )

# üì° Connexion √† l'index
index = pc.Index(PINECONE_INDEX_NAME)

# üîç Fonction pour charger les documents d‚Äôun dossier
def load_documents(folder_path):
    documents = []
    supported_exts = {"pdf", "docx", "doc", "txt", "html", "md"}

    for filename in os.listdir(folder_path):
        filepath = os.path.join(folder_path, filename)
        ext = filename.lower().split('.')[-1]

        if ext not in supported_exts:
            print(f"‚ö†Ô∏è Format non support√© : {filename}")
            continue

        try:
            if ext == "pdf":
                loader = PyPDFLoader(filepath)
            elif ext in ["docx", "doc"]:
                loader = UnstructuredWordDocumentLoader(filepath)
            elif ext == "txt":
                loader = TextLoader(filepath)
            elif ext == "html":
                loader = UnstructuredHTMLLoader(filepath)
            elif ext == "md":
                loader = UnstructuredMarkdownLoader(filepath)

            docs = loader.load()
            documents.extend(docs)
            print(f"üìÑ Document charg√© : {filename} ‚Üí {len(docs)} page(s)")
        except Exception as e:
            print(f"‚ùå Erreur avec {filename} : {e}")
    return documents

# ‚úÇÔ∏è Fonction de d√©coupage intelligent
def split_documents(documents):
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    return splitter.split_documents(documents)

# üîÅ Fonction principale d‚Äôingestion
def main():
    print("üì• D√©marrage de l'ingestion...")
    docs = load_documents(DOCS_FOLDER)
    print(f"üì¶ Total documents bruts : {len(docs)}")

    docs_split = split_documents(docs)
    print(f"üß© Chunks extraits : {len(docs_split)}")

    embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    LangchainPinecone.from_documents(
        documents=docs_split,
        embedding=embedding,
        index_name=PINECONE_INDEX_NAME,
        text_key="page_content"
    )

    print("‚úÖ Ingestion termin√©e. Documents index√©s avec succ√®s.")

if __name__ == "__main__":
    main()